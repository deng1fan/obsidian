---
Type: unpublished
Authors: Yoonna Jang, Jungwoo Lim, Yuna Hur, Dongsuk Oh, Suhyune Son, Yeonsoo Lee, Donghoon Shin, Seungryong Kim, Heuiseok Lim
Year: 2022
Title: Call for Customized Conversation: Customized Conversation Grounding Persona and Knowledge
Journal: arxiv:2112.08619 [cs]
DOI: 
Publisher: arXiv
---

#  (2022)Call for Customized Conversation: Customized Conversation Grounding Persona and Knowledge
###                  ——Yoonna Jang, Jungwoo Lim, Yuna Hur, Dongsuk Oh, Suhyune Son, Yeonsoo Lee, Donghoon Shin, Seungryong Kim, Heuiseok Lim
[*Read it now! See in Zotero*](zotero://select/items/@CallCustomizedConversation2022jang)
**Web:** [Open online](http://arxiv.org/abs/2112.08619)
**Citekey:** CallCustomizedConversation2022jang
**Tags:**  #数据集, #角色加知识
**Code:** [*Available Here*](https://github.com/pkchat-focus/FoCus)


## 摘要
Humans usually have conversations by making use of prior knowledge about a topic and background information of the people whom they are talking to. However, existing conversational agents and datasets do not consider such comprehensive information, and thus they have a limitation in generating the utterances where the knowledge and persona are fused properly. To address this issue, we introduce a call For Customized conversation (FoCus) dataset where the customized answers are built with the user's persona and Wikipedia knowledge. To evaluate the abilities to make informative and customized utterances of pre-trained language models, we utilize BART and GPT-2 as well as transformer-based models. We assess their generation abilities with automatic scores and conduct human evaluations for qualitative results. We examine whether the model reflects adequate persona and knowledge with our proposed two sub-tasks, persona grounding (PG) and knowledge grounding (KG). Moreover, we show that the utterances of our data are constructed with the proper knowledge and persona through grounding quality assessment.

## 总结
[论文分享视频](https://www.bilibili.com/video/BV1na411s7vj/?vd_source=15b1ecaee67a0e28fcffaa484b6d5482)
  
## 研究动机
![[Pasted image 20220630120651.png]]

## 研究背景/ 问题描述
![[Pasted image 20220630120642.png]]

## 方法的创新点
![[Pasted image 20220630120810.png]]
![[Pasted image 20220630121123.png]]
![[Pasted image 20220630121239.png]]
![[Pasted image 20220630121323.png]]
![[Pasted image 20220630121455.png]]
![[Pasted image 20220630121543.png]]

## Baselines
1、transformer decoder
2、transformer encoder-decoder
3、GPT-2
4、BART

## 实验评测
![[Pasted image 20220630121559.png]]
![[Pasted image 20220630121657.png]]
![[Pasted image 20220630121748.png]]
![[Pasted image 20220630121840.png]]
## 实验结论
![[Pasted image 20220630121924.png]]
## 笔记
