> 幻觉性问题是自然语言处理领域中的基础问题之一，指文本生成模型的生成结果中含有与输入事实上冲突的内容。幻觉性问题影响的词语更少，难以被现有指标检测，但在实际应用中的破坏性却更强。大模型的兴起使得幻觉性问题受到了更多的关注，本文梳理了幻觉性问题相关研究的发展历程，展现了幻觉性问题在各个文本生成子领域中的影响与应对手段。


## 幻觉性问题简介

幻觉最初是一个心理学名词，指的是清醒状态下的人类在没有外部对应刺激时产生的虚假感知。自然语言处理领域借用了幻觉这一概念，如果我们将文本生成模型视作“清醒的人类”，那么幻觉指的就是生成结果中出现了不合理或不真实的内容，这些内容无法从输入中得到求证。

值得注意的是，有幻觉性问题的文本并不一定存在语法错误，它们可能像指鹿为马的故事一样，看上去非常的流畅且自然，但却有严重的事实错误，其影响相比语法错误更为隐蔽但破坏性更大。

文本生成任务中的幻觉可以被具体细分为两种：

![图1](../../../_resources/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E5%B9%BB%E8%A7%89%E9%97%AE%E9%A2%98/0dbf25f419bfd6202db049aa4d48b1ac_MD5.png)

第一种幻觉称为**内在幻觉**，其特征是onsensical，也即不合理。如图1左所示，输入为一个苹果的信息但模型生成了香蕉的描述，输入与输出之间明显不一致，这也正是内在幻觉的典型特征：输出与输入显式冲突，用旁观者的角度来看就是“How can it be？”

第二种幻觉称为**外在幻觉**，其特征是Unfaithful，也即不忠于原文。图1右展示了外在幻觉的表现，模型对苹果添油加醋，描述其颜色和品种等信息。尽管这些信息可能是真实的，但在输入信息中没有相应内容，也就无法进行确证。这一类情况用旁观者的角度来看就是“How do you know that？”，也被视作幻觉的一种。

接下来我会举例来详细说明两类幻觉的表现。以图2为例，输入信息为20年发布的关于埃博拉病毒和疫苗的文本，文中表示埃博拉病毒的疫苗在2019年被批准，但新冠疫苗今年可能不会研发完成。

![图2](../../../_resources/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E5%B9%BB%E8%A7%89%E9%97%AE%E9%A2%98/4ef12586bdc780be1638901c0814fbca_MD5.png)

图2下半部分表格前三条错误信息对应生成文本中的关系、实体、情境错误，它们都是内在幻觉的一种表现，与原文相比我们也很明显能够发现其中的事实性错误。表格中最后一条文本表示中国已经开始了新冠疫苗的医学实验，虽然根据外部知识这一点符合事实，但文本中完全没有相关记录，也就说明这是一种外在幻觉。

从这些例子中可以看出，内在幻觉出现了与输入信息的矛盾，是必然需要着重避免的，但外在幻觉只是信息不存在于输入中，其正误并不确定，在一些情况下，外在幻觉甚至是可以利用的对象。

文本生成领域中不同任务对幻觉的态度不尽相同。如果对文本生成领域做一个简单的划分，总体上可以视作非开放生成与开放生成两类。

![图3](../../../_resources/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E5%B9%BB%E8%A7%89%E9%97%AE%E9%A2%98/de1c79ef8f62038a246a66136f1dbf51_MD5.png)

如图3所示，对于摘要、翻译等非开放生成任务，输出内容的信息应当是输入内容的严格子集，这种情况下内在与外在幻觉都是需要避免的，模型需要保证输出与输入信息的事实性一致。而对于故事生成等开放生成任务，输入并不是输出的严格超集，模型需要在外部幻觉中寻找事实正确的部分，也即利用可验证的幻觉。

如果将目光从文本生成上进一步拓宽，知识图谱的一些任务也和幻觉有某些相似之处。如图谱补全寻找的链接并不在原图中，也可以被视作一种幻觉。在这种观点下，知识图谱补全与知识探测都是对幻觉的发掘与利用。  

## 幻觉性问题的成因与评估指标

在观察完幻觉性的表现之后，我们再来分析幻觉问题的来源。一个很显然的来源就是输入数据本身：如果数据集中的输入输出之间存在差异，那么模型在训练过程中就会受到幻觉的干扰。

在数据角度，其最大问题——尤其是对于有限制生成任务而言——是未受指导的生成。以数据到文本任务为例，如果生成结果中含有输入数据中未覆盖的部分，模型就只能对这些内容自由发挥，自然不可避免地产生幻觉；在任务角度，不可忽视的原因是任务输入输出的先天差异，如对话任务中的输入很可能只是一个提示，模型需要外部知识的指导才能得到正确结果。

![图4](../../../_resources/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E5%B9%BB%E8%A7%89%E9%97%AE%E9%A2%98/22c1296a1a0dfa3ea63e35fdc32babbc_MD5.png)

在数据之外，文本生成模型也同样是幻觉的一个重要来源。现在的文本生成模型一般采用自回归的编码-解码器结构，将输入编码为隐藏状态后解码得到生成结果，解码器在生成过程中也会将之前生成的内容作为特征之一。由于预训练语言模型的成功，近年模型常常将其作为编码与解码器。

在这个系统之中，每一步都有产生幻觉的潜在可能。编码器对文本进行编码时，学习到的编码可能并不完美，尤其是对于低频长尾实体信息，预训练语料与精调语料都不足，得到的向量表示就会对之后步骤造成干扰；解码器在解码的过程中可能计算出错误的注意力矩阵，将其他位置的信息错误赋予当前位置，从而产生幻觉。

在解码过程中，自回归模型需要使用之前的解码结果作为输入的一部分。训练过程中模型会使用标准输入，但推断时使用的却是之前的解码结果，这一区别一般被称为曝光误差（exposure bias），也是幻觉的来源之一。除此之外，被广泛使用的大规模预训练语言模型中本身以参数形式存在一些“知识，这些信息不存在于输入中，也是幻觉的一部分。

由于幻觉性问题的普遍性，寻找一些衡量幻觉程度的指标是必要的。ROUGE、BLEU、METEOR等常见的文本生成评估标准均基于单词级别的相似度，但幻觉问题影响的单词数量可能很少，使得这些指标难以衡量文本中的幻觉问题。在研究过程中，研究者提出了多种评估文本幻觉性程度的标准。

![图5](https://mmbiz.qpic.cn/mmbiz_png/1tc1XVsYnZuCicXNPVBZW1vYTmE7VnkS1X8mred0ibGibMjNBBnhHjk5gdXIiaPcN1sodmp5qL0AiaoAOXDRvFzmQ2Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

幻觉性检测的根本目的是评估输入文本与生成结果间的事实一致性。图5展示了三种评估幻觉性的不同思路：第一种思路基于利用信息抽取系统，将事实抽取成三元组后对三元组进行文本相似性评估来检测文本中的幻觉性。这种思路**可解释性好**，但会受到信息抽取系统本身精确度的影响，同时较难比较同义文本。第二种思路基于自然语言理解（NLI）模式，直接将幻觉检测视作文本对的分类任务，训练自然语言理解模型来判断输出结果中的信息能否被输入信息所证实。这一思路**便于训练**，但需要训练数据的支持。第三种思路基于问答（QA）模式，基于文本设计问题后分别使用输入文本与生成结果作为背景知识对问题进行回答，对回答结果进行比对以判断文本的幻觉性。由于问答可以使用多选题的形式，这一思路避免了信息抽取难以比较同义文本的问题，具有**更强的鲁棒性**，被广泛运用于人工评测之中。但相应地，问题与答案选项的质量会严重影响最终的评估可信度。

除此之外，还有一些跳出文本对比较的其他思路，如以正常输入和空输入分别精调两个预训练语言模型，观察两者生成结果的重合度，将与空输入模型的生成结果一致的部分视为幻觉。这一思路新巧地**规避预训练语言模型中本身的幻觉信息**。

## 幻觉性问题的相关研究  

  

![图6](../../../_resources/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E5%B9%BB%E8%A7%89%E9%97%AE%E9%A2%98/5b38b225b371136effd867ad9e02991b_MD5.png)

如图6所示，对幻觉性问题的研究发展可以分为三个阶段：最早也是最广泛的研究是幻觉缓解，也即研究如何减少文本中的幻觉问题，从而保证生成结果的事实正确；之后，研究者发现幻觉性的评估过多依赖于人工评测，成本较高且难以统一复现，由此引出了第二阶段对幻觉性评估标准的研究；多种标准被提出后，由于这些评估标准大多依赖神经网络模型，难以进行直观解释，因此又有学者提出了元评估任务，也即对评价指标进行评估，与人类评测结果相比较以选出最合理的评价指标。这三阶段的任务层层递进，表现了学界对于幻觉问题的认知进步。下文会以文本摘要领域对幻觉性问题的数篇相关论文为例，展示这三个阶段任务的研究方法。

![图7](../../../_resources/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E5%B9%BB%E8%A7%89%E9%97%AE%E9%A2%98/460d4f3a29ba2245a5e60a0e7d08e165_MD5.png)

Luyang Huang等人发表于ACL 2020的论文Knowledge Graph-Augmented Abstractive Summarization with Semantic-Driven Cloze Reward注意到了文本摘要中的幻觉性问题，并尝试使用知识图谱的手段进行缓解。该论文使用信息抽取系统OpenIE提取了原文中的三元组，以此构建了一个“伪知识图谱用来表征输入文本中的事实。论文中的模型使用GAT网络综合了图谱中的信息之后，结合注意力机制将其与语义信息综合，从而在生成结果中添加事实性信息。此外，论文还提出了一个基于强化学习的问答子系统，可以随机替换三元组中的内容后构造问题与答案，从而作为副任务强化模型效果。

![图8](../../../_resources/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E5%B9%BB%E8%A7%89%E9%97%AE%E9%A2%98/7d9239189a61e89acc694d457d4a08a3_MD5.png)

EMNLP 2020的工作FactCC则试图对文本的幻觉性程度进行评估。论文将文本摘要领域中的幻觉性进一步细分为正误错误、实体错误等多种类型，并在标准的数据集上通过多种方式人工加入噪声来构建专注于幻觉检测的数据集。该工作基于NLI思路来判别生成结果中是否有幻觉，通过BERT模型得到文本表示后训练分类器进行判别。实验结果显示，训练出来的判别器在判别文本幻觉性的能力上超越了通用的NLI模型。

![图9](../../../_resources/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%AD%E7%9A%84%E5%B9%BB%E8%A7%89%E9%97%AE%E9%A2%98/fcd40455f9719dfa15c00bffff43b3aa_MD5.png)

发表于NAACL 2021的数据集FRANK则服务于元评估任务，致力于评价不同幻觉性评估标准的合理性。该工作分析发现在不同数据集上，不同模型生成结果的错误类型分布也不同，选取不当可能会导致幻觉评估过多集中在某一种错误上，产生过拟合的问题。因此，作者在两个常见数据集CNN/DM与XSum上对多种模型的摘要结果进行了人工标注，人工确定了每个摘要结果中幻觉性的严重程度，构建了元评估数据集FRANK。评测时，作者观察了多种不同幻觉性评估标准分数与人工评估结果分数之间的相关性，认为相关性更高的评估标准评价效果更好。

## 总结

幻觉性问题是文本生成领域的根本问题之一，它的表现形式多种多样，且难以被简单的统计学指标检测。在进行文本生成任务时，除了保证生成文本的通顺之外还需要减少其中的幻觉，以避免虚假信息对实际应用的负面影响。  

#### 参考文献

[1] Ji, Ziwei, et al. "Survey of Hallucination in Natural Language Generation." arXiv preprint arXiv:2202.03629 (2022).

[2] Li, Wei, et al. "Faithfulness in Natural Language Generation: A Systematic Survey of Analysis, Evaluation and Optimization Methods." arXiv preprint arXiv:2203.05227 (2022).

[3] Dziri, Nouha, et al. "On the Origin of Hallucinations in Conversational Models: Is it the Datasets or the Models?." arXiv preprint arXiv:2204.07931 (2022).

[4] Kryściński, Wojciech, et al. "Neural Text Summarization: A Critical Evaluation." Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). 2019.

[5] Kryściński, Wojciech, et al. "Evaluating the Factual Consistency of Abstractive Text Summarization." Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2020.

[6] Pagnoni, Artidoro, Vidhisha Balachandran, and Yulia Tsvetkov. "Understanding Factuality in Abstractive Summarization with FRANK: A Benchmark for Factuality Metrics." Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021.

[7] Huang, Luyang, Lingfei Wu, and Lu Wang. "Knowledge graph-augmented abstractive summarization with semantic-driven cloze reward." arXiv preprint arXiv:2005.01159 (2020).