## 【2023】Pointwise Mutual Information Based Metric and Decoding Strategy for Faithful Generation in Document Grounded Dialogs
`IBM Research, AI`    [Arxiv](https://arxiv.org/pdf/2305.12191.pdf)


## 【2023】The Dangers of trusting Stochastic Parrots: Faithfulness and Trust in Open-domain Conversational Question Answering
`Alana AI`    [Arxiv](https://arxiv.org/pdf/2305.16519.pdf)

## 【2023】DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents
`Curai Health`    [Arxiv](https://arxiv.org/pdf/2303.17071.pdf)

## 【2023】The Dark Side of ChatGPT: Legal and Ethical Challenges from Stochastic Parrots and Hallucination
`Zihao Li`    [Arxiv](https://arxiv.org/pdf/2304.14347.pdf)
随机鹦鹉

## 【2023】INSTRUCTEVAL: Towards Holistic Evaluation of Instruction-Tuned Large Language Models
`DeCLaRe Lab`    [Arxiv](https://arxiv.org/pdf/2306.04757.pdf)
Hence, this suggests that it is more impactful for resource-constrained researchers and developers to focus on more effective instruction datasets and training methods rather than model size.
因此，这表明，对于资源有限的研究人员和开发人员来说，关注更有效的教学数据集和培训方法比关注模型大小更有影响力。

## 【2022】Survey of Hallucination in Natural Language Generation
`CAiRE`    [Arxiv](https://arxiv.org/pdf/2202.03629.pdf)
综述


